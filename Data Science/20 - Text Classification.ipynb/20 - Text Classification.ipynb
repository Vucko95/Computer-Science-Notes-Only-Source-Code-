{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate a number of applications of text mining, we will use a subset of a corpus of Internet newsgroup articles provided by Scikit-learn.\n",
    "(**Note: this requires a net connection to download the articles**.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# We will only download documents for 2 from 20 newsgroups: Space & Autos\n",
    "newsgroups = fetch_20newsgroups(subset=\"train\", categories=[\"sci.space\",\"rec.autos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the raw documents and the corresponding two class labels for those documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = newsgroups.data\n",
    "target = newsgroups.target\n",
    "target_names = newsgroups.target_names\n",
    "print(\"Dataset has %d documents. Targets are %s\" % (len(documents), set(target_names)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply standard text pre-processing steps to create a document-term matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# we can pass in the same preprocessing parameters\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",min_df = 10)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "print(\"Vocabulary has %d distinct terms\" % len(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a set of sample terms\n",
    "print(terms[200:220])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once we have constructed a document-term matrix, a simple analysis procedure is to identify the most frequent terms (or the highest weighted terms, after TF-IDF is applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum over the columns\n",
    "freqs = X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the indexes of the array by value, and then reverse it\n",
    "sorted_term_indexes = freqs.argsort()\n",
    "sorted_term_indexes = sorted_term_indexes[0, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the top 10 terms\n",
    "for i in range(10):\n",
    "    term_index = sorted_term_indexes[0,i]\n",
    "    print(\"%s = %.2f\" % ( terms[term_index], freqs[0,term_index] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider the annotated class labels (targets) for this corpus subset, a more interesting application to predict a label for newsgroup posts, from one of either of the two classes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "# build a model on the document-term matrix created from the original set of documents\n",
    "model.fit(X, target)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the test data provided by Scikit-learn from the same corpus.\n",
    "(**Note: this requires a net connection to download the articles**.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_newsgroups = fetch_20newsgroups(subset=\"test\", categories=[\"sci.space\",\"rec.autos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = test_newsgroups.data\n",
    "test_target = test_newsgroups.target\n",
    "test_target_names = test_newsgroups.target_names\n",
    "print(\"Test dataset has %d documents. Targets are %s\" % (len(test_documents), set(test_target_names)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert the test set to document-term matrix. Note that we call *transform()* not *fit_transform()*. This ensure that we use the same terms as the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = vectorizer.transform(test_documents)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform predictions, and evaluation the accuracy of those predictions as we saw in previous labs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test_X)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_target, predicted)\n",
    "print(\"Classification accuracy = %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

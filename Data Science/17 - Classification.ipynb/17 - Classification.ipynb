{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Scitkit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification involves using labeled (known) training examples to make an accurate prediction for new unseen input examples. In this lab we will use the classification functionality provided by the Scitkit-learn Python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *k-Nearest Neighbour (KNN) classifier* is a simple but effective \"lazy\"classifier. Given a new input example, it finds the most similar previous examples for which a decision has already been made (i.e. their nearest neighbours from the training set). Based on the majority vote among the K neighbours, a prediction will be made for the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn package includes a number of datasets, which are useful for getting a handle on a given machine learning algorithm before using it in your own work. We will load the version of the Iris dataset which is provided by scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has four different descriptive features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example in the dataset has a class label or a \"target\" from three possible classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a nearest neighbour classifier using $k=1$ nearest neighbour. In this case we will use the full dataset and all of the target labels for those examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test it out by making a prediction for a new input example described by 4 feature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xinput = np.array([[3.0, 5.0, 4.1, 2.0]])\n",
    "# make the prediction, the output is the number of the class\n",
    "pred_class_number = knn.predict(xinput)\n",
    "# to get the name of the class\n",
    "print( iris.target_names[pred_class_number] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict for multiple input examples at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xinput = np.array([[3, 5, 4, 2], [3, 5, 2, 2]])\n",
    "pred_class_numbers = knn.predict(xinput)\n",
    "print( iris.target_names[pred_class_numbers] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Example 2: KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load a CSV copy of the Pima Indian diabetes dataset from the UCI Machine Learning Repository, where the target is to make a prediction of 1 (tested positive for diabetes) or 0 (tested negative for diabetes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CSV file as a numpy matrix\n",
    "raw_dataset = np.loadtxt(\"diabetes.csv\", delimiter=\",\")\n",
    "# the dataset \n",
    "print(raw_dataset.shape)\n",
    "raw_dataset[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV format of the dataset contains data for 768 rows (patients), each with 9 columns. These are 8 descriptive numeric features, and the binary target value. We will separate out the descriptive columns from the target column (i.e. the class labels). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset[:,0:7]\n",
    "target = raw_dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will randomly split the complete dataset into a training test (used to build the model) and an unseen test set (used to try out and evaluate the model). Scikit-learn provides functionality to do this. We will specify that 20% (0.2) of the data will be used for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset_train, dataset_test, target_train, target_test = train_test_split(dataset, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set size is %d\" % dataset_train.shape[0] )\n",
    "print(\"Test set size is %d\" % dataset_test.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fit a k-nearest neighbor model to the data using $k=3$ nearest neighbours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(dataset_train, target_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for the test set, based on the model that we just built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(dataset_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = (predicted == 1).sum()\n",
    "num_neg = (predicted == 0).sum()\n",
    "print( \"Number of patients predicted positive for diabetes: %d\" % num_pos )\n",
    "print( \"Number of patients predicted negative for diabetes: %d\" % num_neg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare our predictions to the \"correct answer\" based on the labels for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions\\n\", predicted)\n",
    "print(\"Correct labels\\n\", target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quantitatively check how accurate these predictions are, by measuring *accuracy*, which will return a value between 0.0 (predictions are completely wrong) and 1.0 (predictions are 100% accurate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(target_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lab we will look at evaluation measures for classification in more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
